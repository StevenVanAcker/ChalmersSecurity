@inproceedings{DelTedesco+:ICISS11,
  author = {F. {Del Tedesco} and S. Hunt and David Sands},
  title = {A Semantic Hierarchy for Erasure Policies},
  booktitle = {Seventh International Conference on Information Systems Security},
  year = 2011,
  xseries = {LNCS},
  publisher = {Springer Verlag},
  pdf = {http://www.cse.chalmers.se/~dave/papers/ICISS11.pdf},
  abstract = {We consider the problem of logical data erasure,
                  contrasting with physical erasure in the same way
                  that end-to-end information flow control contrasts
                  with access control.  We present a semantic
                  hierarchy for erasure policies, using a
                  possibilistic knowledge-based semantics to define
                  policy satisfaction such that there is an
                  intuitively clear upper bound on what information an
                  erasure policy permits to be retained. Our hierarchy
                  allows a rich class of erasure policies to be
                  expressed, taking account of the power of the
                  attacker, how much information may be retained, and
                  under what conditions it may be retained.  While our
                  main aim is to specify erasure policies, the
                  semantic framework allows quite general
                  information-flow policies to be formulated for a
                  variety of semantic notions of secrecy.  }
}

@inproceedings{Mantel+:CSF11,
  author = {Heiko Mantel and David Sands and Henning Sudbrock},
  title = {Assumptions and Guarantees for Compositional
		  Noninterference},
  booktitle = {Proceedings of the 24th IEEE Computer Security Foundations
		  Symposium},
  publisher = {IEEE Computer Society},
  address = {Cernay-la-Ville, France},
  year = 2011,
  pages = {218--232},
  pdf = {http://www.cse.chalmers.se/~dave/papers/CSF2011.pdf},
  abstract = {The idea of building secure systems by plugging together
                  ``secure'' components is appealing, but this
                  requires a definition of security which, in addition
                  to taking care of top-level security goals, is
                  strengthened appropriately in order to be
                  compositional.  This approach has been previously
                  studied for information-flow security of
                  shared-variable concurrent programs, but the price
                  for compositionality is very high: a thread must be
                  extremely pessimistic about what an environment
                  might do with shared resources.  This pessimism
                  leads to many intuitively secure threads being
                  labelled as insecure.  Since in practice it is only
                  meaningful to compose threads which follow an agreed
                  protocol for data access, we take advantage of this
                  to develop a more liberal compositional security
                  condition.  The idea is to give the security
                  definition access to the intended pattern of data
                  usage, as expressed by assumption-guarantee style
                  conditions associated with each thread.  We
                  illustrate the improved precision by developing the
                  first flow-sensitive security type system that
                  provably enforces a noninterference-like property
                  for concurrent programs.  }
}

@inproceedings{Hunt:Sands:ESOP11,
  author = {S. Hunt and David Sands},
  title = {From Exponential to Polynomial-time Security Typing
via Principal Types},
  booktitle = {Programming Languages and Systems. 20th European Symposium on Programming, ESOP 2011},
  xpages = {},
  year = {2011},
  number = {6602},
  series = {LNCS},
  pdf = {http://www.cse.chalmers.se/~dave/papers/Hunt-Sands-ESOP11.pdf},
  publisher = {Springer Verlag},
  abstract = {Hunt and Sands (POPL'06) studied a flow sensitive type
                  (FST) system for multi-level security, parametric in
                  the choice of lattice of security levels.  Choosing
                  the powerset of program variables as the security
                  lattice yields a system which was shown to be
                  equivalent to Amtoft and Banerjee's Hoare-style
                  independence logic (SAS'04). Moreover, using the
                  powerset lattice, it was shown how to derive a
                  principal type from which all other types (for all
                  choices of lattice) can be simply derived. Both of
                  these earlier works gave "algorithmic" formulations
                  of the type system/program logic, but both
                  algorithms are of exponential complexity due to the
                  iterative typing of While loops. Later work by Hunt
                  and Sands (ESOP'08) adapted the FST system to
                  provide an erasure type system which determines
                  whether some input is correctly erased at a
                  designated time. This type system is inherently
                  exponential, requiring a double typing of the
                  erasure-labelled input command. In this paper we
                  start by developing the FST work in two key ways:
                  (1) We specialise the FST system to a form which
                  only derives principal types; the resulting type
                  system has a simple algorithmic reading, yielding
                  principal security types in polynomial time. (2) We
                  show how the FST system can be simply extended to
                  check for various degrees of termination sensitivity
                  (the original FST system is completely termination
                  insensitive, while the erasure type system is fully
                  termination sensitive).We go on to demonstrate the
                  power of these techniques by combining them to
                  develop a type system which is shown to correctly
                  implement erasure typing in polynomial
                  time. Principality is used in an essential way to
                  reduce type derivation size from exponential to
                  linear.}
}

@inproceedings{DelTedesco+:Implementing,
  author = {Filippo {Del Tedesco} and Alejandro Russo and David Sands},
  title = {Implementing Erasure Policies Using Taint Analysis},
  abstract = {Security or privacy-critical applications often require access to
sensitive information in order to function. But in accordance with
the principle of least privilege -- or perhaps simply for legal
compliance -- such applications should not retain said information once
it has served its purpose. In such scenarios, the timely disposal of data
is known as an \emph{information erasure policy}.
This paper studies software-level
information erasure policies for the data manipulated by programs.
The paper presents a new approach to the enforcement of such policies.
We adapt ideas from dynamic taint analysis to track how sensitive data sources propagate through a program and erase them on demand. The method is implemented for Python as a library, with no modifications to the runtime system.
The library is easy to use, and allows programmers to indicate information-erasure policies with only
minor modifications to their code.
},
  optcrossref = {},
  optkey = {},
  booktitle = {The 15th Nordic Conference in Secure IT Systems},
  optpages = {},
  year = {2010},
  editor = {Tuomas Aura},
  optvolume = {},
  optnumber = {},
  series = {LNCS},
  optaddress = {},
  month = {October},
  optorganization = {},
  publisher = {Springer Verlag},
  optnote = {},
  pdf = {http://www.cse.chalmers.se/~dave/papers/erasureTaint.pdf}
}

@inproceedings{Magazinius+:Safe,
  author = {Jonas Magazinius and Phu H. Phung and David Sands},
  title = {Safe Wrappers and Sane Policies for Self Protecting {J}ava{S}cript},
  abstract = { Phung \emph{et al} (ASIACCS'09) describe a method for wrapping built-in
  methods of JavaScript programs in order to enforce security
  policies. The method is appealing because it requires neither deep
  transformation of the code nor browser modification. Unfortunately
  the implementation outlined suffers from a range of vulnerabilities,
  and policy construction is restrictive and error prone. In this paper we address these issues to provide a systematic way to avoid the identified vulnerabilities, and make it easier for the policy writer to construct declarative
policies -- i.e. policies upon which attacker code has no side effects.
},
  booktitle = {The 15th Nordic Conference in Secure IT Systems},
  optpages = {},
  year = {2010},
  editor = {Tuomas Aura},
  optvolume = {},
  optnumber = {},
  series = {LNCS},
  optaddress = {},
  month = {October},
  optorganization = {},
  publisher = {Springer Verlag},
  note = {(Selected papers from AppSec 2010)},
  pdf = {http://www.cse.chalmers.se/~dave/papers/SafeWrappers.pdf}
}

@inproceedings{Broberg:Sands:POPL10,
  author = {Niklas Broberg and David Sands},
  title = {Paralocks -- Role-Based Information Flow Control and Beyond},
  booktitle = {POPL'10, Proceedings of the 37th Annual ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
  year = 2010,
  abstract = {This paper presents Paralocks, a language for building expressive
but statically verifiable fine-grained information flow policies.
Paralocks combine the expressive power of Flow Locks (Broberg \& Sands,
ESOP'06) with the ability to express policies involving run-time
principles, roles (in the style of role-based access control), and
relations (such as ``acts-for'' in discretionary access control).  We
illustrate the Paralocks policy language by giving a simple encoding
of Myers and Liskov's Decentralized Label Model (DLM). Furthermore --
and unlike the DLM -- we provide an information flow semantics for full
Paralock policies.  Lastly we illustrate how Paralocks can be
statically verified by providing a simple programming language
incorporating Paralock policy specifications, and a static type system which
soundly enforces information flow security according to the Paralock
semantics.},
  pdf = {http://www.cse.chalmers.se/~dave/papers/Broberg-Sands-POPL10.pdf}
}

@inproceedings{Svenningsson:Sands:FAST09,
  author = {Josef Svenningsson and David Sands},
  title = {Specification and Verification of Side Channel Declassification},
  booktitle = {The sixth International Workshop on Formal Aspects in Security and Trust (FAST2009) },
  optpages = {},
  year = {2009},
  opteditor = {},
  optvolume = {},
  optnumber = {},
  optseries = {},
  optaddress = {},
  month = {November},
  optorganization = {},
  series = {LNCS},
  publisher = {Springer},
  note = {Pre-proceedings version, plus appendix.},
  pdf = {http://www.cse.chalmers.se/~dave/papers/SS-FAST09.pdf},
  abstract = {Side channel attacks have emerged as a serious threat to the
  security of both networked and embedded systems -- in particular through
  the implementations of cryptographic operations. Side channels can
  be difficult to model formally, but with careful coding and program
  transformation techniques it may be possible to verify security in
  the presence of specific side-channel attacks. But what if a program
  intentionally makes a tradeoff between security and efficiency and
  leaks some information through a side channel? In this paper we
  study such tradeoffs using ideas from recent research on
  declassification. We present a semantic model of security for
  programs which allow for declassification through side channels, and
  show how side-channel declassification can be verified using
  off-the-shelf software model checking tools. Finally, to make it
  simpler for verifiers to check that a program conforms to a
  particular side-channel declassification policy we introduce a
  further tradeoff between efficiency and verifiability: by writing programs
  in a particular ``manifest form'' security becomes considerably easier to
  verify.}
}

@inproceedings{DelTedesco:Sands:Secco09,
  author = {Filippo Del Tedesco and David Sands},
  title = {A User Model for Information Erasure},
  optcrossref = {},
  optkey = {},
  booktitle = {SecCo'09, 7th International Workshop on Security Issues in Concurrency},
  optpages = {},
  year = {2009},
  opteditor = {},
  optvolume = {},
  optnumber = {},
  series = {Electronic Proceedings in Theoretical Computer Science},
  optaddress = {},
  optmonth = {},
  optorganization = {},
  optpublisher = {},
  note = {To appear},
  abstract = { Hunt and Sands (ESOP'08) studied a notion of \emph{information
    erasure} for systems which receive secrets intended for
  limited-time use. Erasure demands that once a secret has fulfilled
  its purpose the subsequent behaviour of the system should reveal
  no information about the erased data. In this paper we address a
  shortcoming in that work: for erasure to be possible the user who
  provides data must also play his part, but previously that role was
  only specified informally. Here we provide a formal model of the
  user and a collection of requirements called \emph{erasure
    friendliness}. We prove that an erasure-friendly user can be
  composed with an erasing system (in the sense of Hunt and Sands) to
  obtain a combined system which is \emph{jointly erasing} in an
  appropriate sense. In doing so we identify stronger requirements on the user than those informally described in the previous work. },
  pdf = {http://www.cse.chalmers.se/~dave/papers/DelTedescoSandsSecCo09.pdf}
}

@inproceedings{Broberg:Sands:PLAS09,
  author = {Niklas Broberg and David Sands},
  title = {Flow-Sensitive Semantics for Dynamic Information Flow Policies},
  booktitle = {ACM SIGPLAN Fourth Workshop on
Programming Languages and Analysis for Security (PLAS 2009)},
  year = 2009,
  editor = {S. Chong and D. Naumann},
  address = {Dublin},
  month = {June 15},
  publisher = {ACM},
  abstract = {Dynamic information flow policies, such as declassification,
are essential for practically useful information flow control systems.
However, most systems proposed to date that handle dynamic information
flow policies suffer from a common drawback. They build on semantic models of security which are inherently flow
insensitive, which means that many simple intuitively secure programs
will be considered insecure.

In this paper we address this problem in the context of a particular
system, flow locks. We provide a new flow sensitive semantics for flow
locks based on a knowledge-style definition (following Askarov and
Sabelfeld), in which the knowledge gained by an actor
observing a program run is constrained according to the flow locks
which are open at the time each observation is made. We demonstrate
the applicability of the definition in a soundness proof for a simple
flow lock type system. We also show how other systems can be encoded
using flow locks, as an easy means to provide these systems with flow
sensitive semantics.},
  pdf = {http://www.cse.chalmers.se/~dave/papers/BrobergSandsPLAS09.pdf}
}

@inproceedings{Phung:Sands:Chudnov:ASIACCS09,
  author = {Phu H. Phung and David Sands and Andrey Chudnov},
  title = {Lightweight Self-Protecting JavaScript},
  booktitle = {ACM Symposium on Information, Computer and Communications Security (ASIACCS 2009)},
  optpages = {},
  year = {2009},
  editor = {R. Safavi-Naini and V. Varadharajan},
  address = {Sydney, Australia},
  month = {March},
  publisher = {ACM Press},
  pdf = {http://www.cse.chalmers.se/~dave/papers/ASIACCS09.pdf},
  abstract = { This paper introduces a method to control
                  JavaScript execution. The aim is to prevent or
                  modify inappropriate behaviour caused by
                  e.g. malicious injected scripts or poorly designed
                  third-party code. The approach is based on modifying
                  the code so as to make it self-protecting: the
                  protection mechanism (security policy) is embedded
                  into the code itself and intercepts security
                  relevant API calls. The challenges come from the
                  nature of the JavaScript language: any variables in
                  the scope of the program can be redefined, and code
                  can be created and run on-the-fly. This creates
                  potential problems, respectively, for
                  tamper-proofing the protection mechanism, and for
                  ensuring that no security relevant events bypass the
                  protection.  Unlike previous approaches to
                  instrument and monitor JavaScript to enforce or
                  adjust behaviour, the solution we propose is
                  \emph{lightweight} in that (i) it does not require a
                  modified browser, and (ii) it does not require any
                  run-time parsing and transformation of code
                  (including dynamically generated code). As a result,
                  the method has low run-time overhead compared to
                  other methods satisfying (i), and the lack of need
                  for browser modifications means that the policy can
                  even be applied on the server to mitigate some
                  effects of cross-site scripting bugs.
  }
}

@techreport{Demange:Sands:ESOPfull,
  author = {D. Demange and David Sands},
  title = {All Secrets Great and Small},
  institution = {Computer Science and Engineering,
                   Chalmers University of Technology},
  number = {2009-01},
  year = {2009},
  pdf = {http://www.cse.chalmers.se/~dave/papers/Demange-Sands-TR09-1.pdf},
  month = {April},
  note = {Extended version of \cite{Demange:Sands:ESOP09}},
  optannote = {}
}

@inproceedings{Demange:Sands:ESOP09,
  author = {D. Demange and David Sands},
  title = {{All Secrets Great and Small}},
  booktitle = {Programming Languages and Systems. 18th European Symposium on Programming, ESOP 2009},
  pages = {207--221},
  year = {2009},
  number = {5502},
  series = {LNCS},
  pdf = {http://www.cse.chalmers.se/~dave/papers/DemangeSandsESOP09.pdf},
  publisher = {Springer Verlag},
  abstract = {
Tools for analysing secure information flow are almost exclusively
based on ideas going back to Denning's work from the 70's. This
approach embodies an imperfect notion of security which turns a blind
eye to information flows which are encoded in the termination
behaviour of a program. In exchange for this weakness many more
programs are deemed ``secure'', using conditions which are easy to
check. Previously it was thought that such leaks are limited to at
most one bit per run. Recent work by Askarov et al (ESORICS'08) offers
some bad news and some good news: the bad news is that for programs
which perform output, the amount of information leaked by a Denning
style analysis is not bounded; the good news is that if secrets are
chosen to be sufficiently large and sufficiently random then they cannot be
effectively leaked at all. The problem addressed in this paper is that
secrets cannot always be made sufficiently large or sufficiently
random. Contrast, for example, an encryption key with an
``hasHIV''-field of a patient record. In recognition of this we develop
a notion of \emph{secret-sensitive noninterference} in which ``small'' secrets
are handled more carefully than ``big'' ones.  We illustrate the idea
with a type system which combines a liberal Denning-style analysis
with a more restrictive system according to the nature of the secrets
at hand.
  }
}

@inproceedings{Askarov+:ESORICS08,
  title = {{Termination-Insensitive Noninterference Leaks More Than Just a Bit}},
  author = {Askarov, A. and Hunt, S. and Sabelfeld, A. and Sands, D.},
  booktitle = {The 13th European Symposium on Research in Computer Security (ESORICS 08, Malaga, Spain, October 6-8, 2008. Proceedings},
  number = {5283},
  series = {LNCS},
  pdf = {http://www.cse.chalmers.se/~andrei/esorics08.pdf},
  publisher = {Springer Verlag},
  abstract = { Current tools for analysing information flow in programs
                  build upon ideas going back to Denning's work from
                  the 70's. These systems enforce an imperfect notion
                  of information flow which has become known as
                  termination-insensitive noninterference. Under this
                  version of noninterference, information leaks are
                  permitted if they are transmitted purely by the
                  program's termination behaviour (i.e., whether it
                  terminates or not). This imperfection is the price
                  to pay for having a security condition which is
                  relatively liberal (e.g. allowing while-loops whose
                  termination may depend on the value of a secret) and
                  easy to check. But what is the price exactly? We
                  argue that, in the presence of output, the price is
                  higher than the ``one bit'' often claimed informally
                  in the literature, and effectively such programs can
                  leak all of their secrets. In this paper we develop
                  a definition of termination-insensitive
                  noninterference suitable for reasoning about
                  programs with outputs. We show that the definition
                  generalises ``batch-job'' style definitions from the
                  literature and that it is indeed satisfied by a
                  Denning-style program analysis with output. Although
                  more than a bit of information can be leaked by
                  programs satisfying this condition, we show that the
                  best an attacker can do is a brute-force attack,
                  which means that the attacker cannot reliably (in a
                  technical sense) learn the secret in polynomial time
                  in the size of the secret. If we further assume that
                  secrets are uniformly distributed, we show that the
                  advantage the attacker gains when guessing the
                  secret after observing a polynomial amount of output
                  is negligible in the size of the secret.  },
  pages = {333--348},
  year = {2008}
}

@unpublished{Hunt:Sands:ESOP08-extended,
  author = {S. Hunt and David Sands},
  title = {Just Forget it -- The Semantics and Enforcement of Information Erasure},
  note = {Extended version of \cite{Hunt:Sands:ESOP08} inluding proofs},
  month = {April},
  year = {2008},
  pdf = {http://www.cse.chalmers.se/~dave/papers/Hunt-Sands-ESOP08-extended.pdf},
  optannote = {}
}

@inproceedings{Phung:Sands:COMPSAC08,
  author = {P. H. Phung and David Sands},
  title = {{Security Policy Enforcement in the OSGi Framework Using Aspect-Oriented Programming}},
  booktitle = {Proceedings of the 32nd Annual IEEE International Computer
               Software and Applications Conference, COMPSAC 2008, 28 July
               -- 1 August 2008, Turku, Finland},
  publisher = {IEEE Computer Society},
  pages = {1076--1082},
  year = {2008},
  isbn = {978-0-7695-3262-2},
  abstract = {
The lifecycle mismatch between vehicles and their IT system
poses a problem for the automotive industry. Such systems
need to be open and extensible to provide customised
functionalities and services. What is less clear is how to
achieve this with quality and security guarantees.
Recent studies in language-based security -- the use of
programming language technology to enforce application
specific security policies -- show that security policy enforcement
mechanisms such as inlined reference monitors
provide a potential solution for security in extensible systems.
In this paper we study the implementation of security
policy enforcement using aspect-oriented programming for
the OSGi (Open Services Gateway initiative) framework.
We identify classes of reference monitor-style policies that
can be defined and enforced using AspectJ, a well-known
aspect-oriented programming language. We demonstrate
the use of security states to describe history-based policies.
We also introduce and implement various levels of security
states in Java to describe session level history versus
global application level history. We illustrate the effectiveness
of the implementation by deploying the security policy
enforcement solution in an example scenario of software
downloading in a standard vehicle system.
},
  pdf = {http://www.cse.chalmers.se/~dave/papers/PhungSandsCOMPSAC08.pdf}
}

@inproceedings{Hunt:Sands:ESOP08,
  author = {S. Hunt and David Sands},
  title = {Just Forget it -- The Semantics and Enforcement of Information Erasure},
  booktitle = {Programming Languages and Systems. 17th European Symposium on Programming, ESOP 2008},
  pages = {239--253},
  year = {2008},
  number = {4960},
  series = {LNCS},
  pdf = {http://www.cse.chalmers.se/~dave/papers/Hunt-Sands-ESOP08.pdf},
  publisher = {Springer Verlag},
  abstract = {There are many settings in which sensitive information is
  made available to a system or organisation for a specific purpose,
  on the understanding that it will be erased once that purpose has
  been fulfilled.  A familiar example is that of online credit card
  transactions: a customer typically provides credit card details to a
  payment system on the understanding that the following promises are
  kept: (i) Noninterference (NI): the card details may flow to the
  bank (in order that the payment can be authorised) but not %the
  merchant; to other users of the system; (ii) Erasure: the payment
  system will not retain any record of the card details once the
  transaction is complete.  This example shows that we need to reason
  about NI and erasure in combination, and that we need to consider
  interactive systems: the card details are used in the interaction
  between the principals, and then erased; without the interaction,
  the card details could be dispensed with altogether and erasure
  would be unnecessary.  The contributions of this paper are as
  follows.  (i) We show that an end-to-end erasure property can be
  encoded as a ``flow sensitive'' noninterference property.  (ii) By a
  judicious choice of language construct to support erasure policies,
  we successfully adapt this result to an interactive setting.  (iii)
  We use this result to design a type system which guarantees that
  well typed programs are properly erasing.  Although erasure policies
  have been discussed in earlier papers, this appears to be the first
  static analysis to enforce erasure.  }
}
